{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022f229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310703f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f0742",
   "metadata": {},
   "source": [
    "# Collecting Corresponding Points from images\n",
    "### we will use:\n",
    "- ginput(n)\n",
    "- numpy.save(path, var) - save variable into binary to path\n",
    "- numpy.load(path) - load that saved variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605fd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def pick_and_save_correspondences(stitching_img_path, base_img_path, n_corresp = 4, sample_name = 'temp' ):\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(23, 16))\n",
    "# collecting correspondances\n",
    "    # Load or create two example images\n",
    "    img1 = mpimg.imread(stitching_img_path)\n",
    "    img2 = mpimg.imread(base_img_path)\n",
    "\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(\"Image 1\")\n",
    "\n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(\"Image 2\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    # Number of points to pick\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    correspondances = []\n",
    "    # Pick points alternately\n",
    "    for i in range(n_corresp):\n",
    "        # take point 1 at img1\n",
    "        print(f\"Select point {i+1} in Image 1\")\n",
    "        plt.sca(ax1)\n",
    "        p1 = plt.ginput(1)[0]\n",
    "        plt.plot(p1[0], p1[1], 'ro')\n",
    "        pts1.append(p1)\n",
    "\n",
    "        # take point 2 at img2\n",
    "        print(f\"Select corresponding point {i+1} in Image 2\")\n",
    "        plt.sca(ax2)\n",
    "        p2 = plt.ginput(1)[0]\n",
    "        plt.plot(p2[0], p2[1], 'go')\n",
    "        pts2.append(p2)\n",
    "\n",
    "        # push correspondance to list\n",
    "        correspondances.append((p1, p2))\n",
    "\n",
    "        # Draw lines showing correspondence across subplots\n",
    "        # Convert axes coordinates to normalised figure coordinates\n",
    "        fig.canvas.draw()\n",
    "        transFigure = fig.transFigure.inverted()\n",
    "        coord1 = ax1.transData.transform(p1)\n",
    "        coord2 = ax2.transData.transform(p2)\n",
    "        fig_coord1 = transFigure.transform(coord1)\n",
    "        fig_coord2 = transFigure.transform(coord2)\n",
    "        line = plt.Line2D((fig_coord1[0], fig_coord2[0]),\n",
    "                        (fig_coord1[1], fig_coord2[1]),\n",
    "                        transform=fig.transFigure,\n",
    "                        color='yellow', linestyle='--')\n",
    "        fig.lines.append(line)\n",
    "        plt.draw()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "    # saving selected points\n",
    "    output_dir = f'./homography/{sample_name}/samples'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    output_fullpath = output_dir + f'/{n_corresp}_corresp'\n",
    "    np.save(output_fullpath, correspondances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc1eea",
   "metadata": {},
   "source": [
    "### Plotting funs used\n",
    "\n",
    ">We have **figure coordinate system (display)** that contains subplots, etc. (`fig`).\n",
    ">Every figure is like a **canvas**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1Ô∏è‚É£ `fig.transFigure.inverted()` vs `fig.transFigure`\n",
    "\n",
    "* **Display (figure) coordinate system** can be:\n",
    "\n",
    "1. **Normalized** `(0,0)` to `(1,1)`\n",
    "\n",
    "   * Independent of the figure size ‚Üí `fig.transFigure` (it's just a coordinate system)\n",
    "   * **MAPping:** `FIG.NORMAL_COORD ‚Üí FIG.PIXEL_COORD` ‚Üí `fig.transFigure.transform(coords)`\n",
    "   * **MAPping:** `FIG.PIXEL_COORD ‚Üí FIG.NORMAL_COORD` ‚Üí `fig.transFigure.inverted().transform(coords)`\n",
    "\n",
    "2. **In pixels**\n",
    "\n",
    "   * Shows actual pixels on the screen\n",
    "   * Depends on the size of the figure window (canvas) ‚Üí `fig.transFigure.inverted()` (it's just coord system for fig in pixels)\n",
    "\n",
    "---\n",
    "\n",
    "#### 2Ô∏è‚É£ `ax_i.transData.transform(x, y)`\n",
    "\n",
    "1. `ax1.transData.transform(x, y)` maps **data points** `(x, y)` on subplot `ax1` to **pixels** in display coordinates (relative to the figure canvas).\n",
    "2. Similarly, `ax2.transData` does the same for subplot `ax2`.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3Ô∏è‚É£ Why do we map clicked points up until getting normalized figure coordinates?\n",
    "\n",
    "* Because we **cannot use `fig.transFigure.inverted` as the transform coordinate system** for drawing lines.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3950cd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select point 1 in Image 1\n",
      "Select corresponding point 1 in Image 2\n",
      "Select point 2 in Image 1\n",
      "Select corresponding point 2 in Image 2\n",
      "Select point 3 in Image 1\n",
      "Select corresponding point 3 in Image 2\n",
      "Select point 4 in Image 1\n",
      "Select corresponding point 4 in Image 2\n",
      "Select point 5 in Image 1\n",
      "Select corresponding point 5 in Image 2\n"
     ]
    }
   ],
   "source": [
    "# collecting correspondances\n",
    "im1_path = './images/paris/paris_c.jpg'\n",
    "im2_path = './images/paris/paris_b.jpg' # (BASE IMG)\n",
    "\n",
    "#result_path = result_root_dir + os.path.basename(im1_path)\n",
    "for sample_size in [5]:\n",
    "    pick_and_save_correspondences(im1_path, im2_path, sample_size, sample_name=f'paris/H_cb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b197041",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = './homography/cmpe_building/left1_left2/samples/4_corresp.npy'\n",
    "\n",
    "def homography_by_sample(sample_path):\n",
    "    # load saved sample info\n",
    "    points_data = np.load(sample_path)\n",
    "\n",
    "    # compute homography\n",
    "    points_im1 = points_data[:, 0]\n",
    "    points_im2 = points_data[:, 1]\n",
    "\n",
    "    return computeH(points_im1, points_im2)\n",
    "\n",
    "def computeH(points_im1, points_im2):\n",
    "\n",
    "    # constructing CALIBRATION MATRIX\n",
    "    X1 = points_im1[:, 0]\n",
    "    Y1 = points_im1[:, 1]\n",
    "\n",
    "    ones = np.ones_like(X1)\n",
    "    zeros = np.zeros_like(X1)\n",
    "\n",
    "    X2 = points_im2[:, 0]\n",
    "    Y2 = points_im2[:, 1]\n",
    "\n",
    "    # last 3 columns of rows of type-1\n",
    "    NX2X1 = -1 * X2 * X1\n",
    "    NX2Y1 = -1 * X2 * Y1\n",
    "    NX2 = -1 * X2\n",
    "\n",
    "    # last 3 columns of other rows\n",
    "    NY2X1 = -1 * Y2 * X1\n",
    "    NY2Y1 = -1 * Y2 * Y1\n",
    "    NY2 = -1 * Y2\n",
    "\n",
    "    row1 = np.stack([X1, Y1, ones, zeros, zeros, zeros, NX2X1, NX2Y1, NX2], axis = 1)\n",
    "    row2 = np.stack([zeros, zeros, zeros, X1, Y1, ones, NY2X1, NY2Y1, NY2], axis = 1)\n",
    "\n",
    "    A_matrix = np.vstack([row1, row2])\n",
    "\n",
    "    # compute svd for minimisation problem: h = argmin_h(Ah)\n",
    "    U, S, Vt = np.linalg.svd(A_matrix)\n",
    "    # solution is last row of V\n",
    "    h = Vt[-1, :]\n",
    "    H = h.reshape(3,3)\n",
    "\n",
    "    # normalised solution to right-bottom corner element\n",
    "    H = (H / H[2,2])\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267552f",
   "metadata": {},
   "source": [
    "## üåÄ Warping Image\n",
    "\n",
    "### 0) Why not Forward Warping?\n",
    "\n",
    "We **don‚Äôt use forward warping** because it‚Äôs inefficient and produces artifacts.\n",
    "Since real images contain **noise** and **picked correspondence points aren‚Äôt perfectly accurate**,\n",
    "some points in `img1` may get mapped to the **same pixel** in `img2` plane by the homography $ H_{12} $.\n",
    "\n",
    "As a result, when we compute\n",
    "\n",
    "$\n",
    "(x', y', 1)^T = H_{12} \\cdot (x, y, 1)^T\n",
    "$\n",
    "\n",
    "the set of mapped pixels ${(x', y')}$ may **not cover every pixel** in the target image ‚Äî\n",
    "causing **holes** (unfilled regions) where no source pixel lands.\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Backward Warping Idea\n",
    "\n",
    "The idea is simple:\n",
    "we **invert the mapping** and instead ask:\n",
    "\n",
    "> ‚ÄúFor each pixel (x‚Ä≤, y‚Ä≤) in the output image (img2 plane),\n",
    "> from which location (x, y) in img1 should its color come?‚Äù\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$\n",
    "\\text{color}(x', y') = \\text{color}*{\\text{img1}}(H*{12}^{-1} \\cdot (x', y', 1)^T)\n",
    "$\n",
    "\n",
    "So for every output pixel, we **trace it backward** through $ H_{12}^{-1} $\n",
    "to find where it came from in `img1`.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1) Constructing All (x‚Ä≤, y‚Ä≤, 1) Points\n",
    "\n",
    "To apply $ H_{12}^{-1} $ to **all output pixels at once**,\n",
    "we create a grid of all pixel coordinates on the output (img2) plane.\n",
    "\n",
    "We use **`np.meshgrid`** to generate all $(x‚Ä≤, y‚Ä≤)$ combinations:\n",
    "\n",
    "Perfect ‚Äî here‚Äôs a clear explanation (with math) of **how `np.meshgrid` builds the full coordinate matrix** used in backward warping üëá\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Constructing the Coordinate Matrix with `np.meshgrid`\n",
    "\n",
    "Let‚Äôs say your **output image** (the plane we warp onto) has size:\n",
    "\n",
    "$\n",
    "\\text{height} = h_{out}, \\quad \\text{width} = w_{out}\n",
    "$\n",
    "\n",
    "So, pixel coordinates on this image are integer grid points:\n",
    "\n",
    "$\n",
    "x' \\in [0, w_{out}-1], \\quad y' \\in [0, h_{out}-1]\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### 1Ô∏è‚É£ Build coordinate grids\n",
    "\n",
    "We use:\n",
    "\n",
    "```python\n",
    "xs, ys = np.meshgrid(np.arange(w_out), np.arange(h_out))\n",
    "```\n",
    "\n",
    "* `np.arange(w_out)` ‚Üí `[0, 1, 2, ..., w_out-1]`  ‚Üí **x-coordinates**\n",
    "* `np.arange(h_out)` ‚Üí `[0, 1, 2, ..., h_out-1]` ‚Üí **y-coordinates**\n",
    "* `meshgrid` repeats them to form **full 2D coordinate grids**:\n",
    "\n",
    "Example (for `w_out=3`, `h_out=2`):\n",
    "\n",
    "```python\n",
    "xs =\n",
    "[[0, 1, 2],\n",
    " [0, 1, 2]]\n",
    "\n",
    "ys =\n",
    "[[0, 0, 0],\n",
    " [1, 1, 1]]\n",
    "```\n",
    "\n",
    "That means:\n",
    "\n",
    "* first row of `xs, ys` corresponds to y=0 (top row of image)\n",
    "* second row corresponds to y=1, etc.\n",
    "Together they define a mesh of coordinate pairs:\n",
    "\n",
    "```scss\n",
    "    (0,0) (1,0) (2,0)\n",
    "    (0,1) (1,1) (2,1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Flatten into column form\n",
    "\n",
    "We flatten both to 1D arrays:\n",
    "\n",
    "```python\n",
    "x_flat = xs.ravel()\n",
    "y_flat = ys.ravel()\n",
    "```\n",
    "\n",
    "Result:\n",
    "\n",
    "$\n",
    "x_{flat} = [0, 1, 2, 0, 1, 2]\n",
    "$\n",
    "$\n",
    "y_{flat} = [0, 0, 0, 1, 1, 1]\n",
    "$\n",
    "\n",
    "Each pair ((x_i', y_i')) corresponds to **one pixel** in the output image.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Convert to homogeneous coordinates\n",
    "\n",
    "Add a third coordinate = 1 for all points:\n",
    "\n",
    "```python\n",
    "ones = np.ones_like(x_flat)\n",
    "```\n",
    "\n",
    "Then **stack** them as rows (axis=0):\n",
    "\n",
    "```python\n",
    "p2_h = np.stack([x_flat, y_flat, ones], axis=0)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ Resulting matrix shape\n",
    "\n",
    "`p2_h` is a **3√óN matrix**, where $ N = h_{out} \\times w_{out} $.\n",
    "\n",
    "$\n",
    "p_2^h =\n",
    "\\begin{bmatrix}\n",
    "x'_1 & x'_2 & \\dots & x'_N \\\\\n",
    "y'_1 & y'_2 & \\dots & y'_N \\\\\n",
    "1 & 1 & \\dots & 1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Each column corresponds to **where img2 pixel comes from, if it was on plane img1**.\n",
    "---\n",
    "\n",
    "### 5Ô∏è‚É£ Why this form?\n",
    "\n",
    "This form allows us to apply the inverse homography to *all pixels at once* using matrix multiplication:\n",
    "\n",
    "$\n",
    "p_1^h = H_{12}^{-1} \\cdot p_2^h\n",
    "$\n",
    "\n",
    "which efficiently gives the mapped coordinates ((x, y)) in the source image for **every output pixel**.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Interpolating and Color setting at once\n",
    "\n",
    "### 1Ô∏è‚É£ Ideal mathematical model (no noise, integer coordinates)\n",
    "\n",
    "If your homography were **perfect** and pixel-aligned, then for each pixel ((x',y')) on the **output image (img2 plane)**,\n",
    "you‚Äôd find its corresponding pixel ((x,y)) on **img1 plane** as:\n",
    "\n",
    "$\n",
    "[x, y, 1]^T ;=; H^{-1} [x', y', 1]^T\n",
    "$\n",
    "\n",
    "and ideally, those ((x,y)) would be **integers** (exact pixel centers).\n",
    "So, the color mapping is:\n",
    "\n",
    "$\n",
    "\\text{color}*{\\text{out}}(x',y') ;=; \\text{color}*{\\text{img1}}(x,y)\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Real-world case (noise, non-integer mappings) - OUR CASE\n",
    "\n",
    "To get the color, we interpolate between the four neighboring pixels around ((x,y)):\n",
    "\n",
    "$\n",
    "\\text{color}_{\\text{img2}}(x',y') = \\text{color}_{\\text{img1}}\\big( \\text{Interpolation}(H^{-1} [x', y', 1]^T) \\big)\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Intuitive explanation\n",
    "\n",
    "* $H^{-1}$ tells **where this pixel on the output came from** on img1.\n",
    "* That source coordinate may not be an integer pixel ‚Üí so we **interpolate** color from nearby pixels in img1.\n",
    "* That‚Äôs why we say ‚Äúbackward warping‚Äù:\n",
    "  we go **back** from output ‚Üí input to **sample** colors smoothly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb86a9",
   "metadata": {},
   "source": [
    "## Making Warped Part Visible ‚Äî `warp_full`\n",
    "\n",
    "1. Apply transform so all warped corners have positive coordinates:  \n",
    "   $$\n",
    "   H_{\\text{adjusted}} = \n",
    "   \\begin{bmatrix}\n",
    "   1 & 0 & -x_{\\min}\\\\\n",
    "   0 & 1 & -y_{\\min}\\\\\n",
    "   0 & 0 & 1\n",
    "   \\end{bmatrix} H\n",
    "   $$\n",
    "   ensuring $ H_{\\text{adjusted}}^{-1}(x_b, y_b, 1) = (x, y, 1) $ lies in image grid.  \n",
    "\n",
    "2. Set output size to  \n",
    "   $$\n",
    "      W = \\lceil x_{\\max} - x_{\\min} \\rceil, \\quad \n",
    "      H = \\lceil y_{\\max} - y_{\\min} \\rceil,\n",
    "   $$\n",
    "   so all backward-transformed points fit within the visible output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a29cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp(image, homography, output_shape=None):\n",
    "    h_in, w_in = image.shape[:2]\n",
    "\n",
    "    if output_shape is None:\n",
    "        # get sizes of image (it's img1)\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "    else:\n",
    "        height, width = output_shape\n",
    "\n",
    "    # get matrix of all points as columns\n",
    "    x_axis = np.arange(width)\n",
    "    y_axis = np.arange(height)\n",
    "\n",
    "    # rows we will stack for the matrix\n",
    "    x_mesh, y_mesh = np.meshgrid(x_axis, y_axis)\n",
    "    ones = np.ones_like(np.ravel(x_mesh))\n",
    "    \n",
    "    # A is matrix of all points in homogeneos coord.sys for plane 2\n",
    "    P2 = np.stack([np.ravel(x_mesh), np.ravel(y_mesh), ones], axis = 0)\n",
    "\n",
    "    # now, we need to get colors of them by backward transform\n",
    "    P21 = np.dot(np.linalg.inv(homography), P2 )\n",
    "    P21 = P21 / P21[2,:]\n",
    "    \n",
    "    # interpolating with opencv function\n",
    "    \n",
    "    # 1. get coordinate maps\n",
    "    x_map = P21[0, :].reshape(height, width).astype(np.float32)\n",
    "    y_map = P21[1, :].reshape(height, width).astype(np.float32)\n",
    "\n",
    "    # 2. using interpolation function opencv that also makes mapping of colors\n",
    "    warped_image = cv2.remap(image, x_map, y_map ,interpolation = cv2.INTER_LINEAR, borderMode = cv2.BORDER_CONSTANT, borderValue=0)\n",
    "    \n",
    "    # return interpolated and remaped \n",
    "    return warped_image\n",
    "\n",
    "\n",
    "def warp_full(image, homography):\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Find corners and warp them\n",
    "    corners = np.array([[0, 0, 1],\n",
    "                        [w, 0, 1],\n",
    "                        [w, h, 1],\n",
    "                        [0, h, 1]]).T\n",
    "    warped_corners = homography @ corners\n",
    "    warped_corners /= warped_corners[2, :]\n",
    "    xs, ys = warped_corners[0], warped_corners[1]\n",
    "\n",
    "    # Translate original corners to BASE img. plane\n",
    "    xmin, xmax = xs.min(), xs.max()\n",
    "    ymin, ymax = ys.min(), ys.max()\n",
    "\n",
    "    # Get Translation matrix, making adjusted Homography\n",
    "    trans = np.array([[1, 0, -xmin],\n",
    "                      [0, 1, -ymin],\n",
    "                      [0, 0, 1]])\n",
    "    \n",
    "    # H_adj_inverse will now, make base coord. to map at coorners of original img.\n",
    "    # So that in Backward Transform. we will not have points outside original image plane.\n",
    "    H_adj = trans @ homography\n",
    "\n",
    "    out_w, out_h = int(np.ceil(xmax - xmin)), int(np.ceil(ymax - ymin))\n",
    "    return warp(image, H_adj, (out_h, out_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518bf23",
   "metadata": {},
   "source": [
    "## Task Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b0463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic(images, homographies):\n",
    "    # Frist: we need to get translation vector for resulting image \n",
    "    # to have all coords poisitive to be visible\n",
    "    \n",
    "    # 1. get all corners warped\n",
    "    all_warped_corners = []\n",
    "    for image, homography in zip(images, homographies):\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        # Find corners and warp them\n",
    "        corners = np.array([[0, 0, 1],\n",
    "                            [w, 0, 1],\n",
    "                            [w, h, 1],\n",
    "                            [0, h, 1]]).T\n",
    "        \n",
    "        warped_corners = homography @ corners\n",
    "        warped_corners /= warped_corners[2, :]\n",
    "        all_warped_corners.append(warped_corners)\n",
    "    all_warped_corners = np.hstack(all_warped_corners)\n",
    "\n",
    "    # getting global corners for total mosaic\n",
    "    x_min = all_warped_corners[0].min()\n",
    "    x_max = all_warped_corners[0].max()\n",
    "    y_min = all_warped_corners[1].min()\n",
    "    y_max = all_warped_corners[1].max()\n",
    "\n",
    "    # getting global Translation Matrix for making total mosaic visible\n",
    "    T = np.array(\n",
    "        [[1, 0, -x_min],\n",
    "         [0, 1, -y_min],\n",
    "         [0, 0,   1   ]])\n",
    "    \n",
    "    # getting total img (canvas) size for output img\n",
    "    w_out = int(np.ceil(x_max - x_min))\n",
    "    h_out = int(np.ceil(y_max - y_min))\n",
    "\n",
    "    # getting warped imgs.\n",
    "    warped_imgs = [warp(img, T @ homography, output_shape = (h_out, w_out) ) \n",
    "                   for img, homography in zip(images, homographies)]\n",
    "    return warped_imgs\n",
    "\n",
    "def blend(images):\n",
    "    # basic maximum intensity blending\n",
    "    blended_mosaic = np.zeros_like(images[0], dtype = np.float32)\n",
    "    for image in images:\n",
    "        blended_mosaic = np.maximum(blended_mosaic, image)\n",
    "    # clip any overflows\n",
    "    return np.clip(blended_mosaic ,0 ,255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a4505",
   "metadata": {},
   "source": [
    "### Task 1 ‚Äî Paris\n",
    "\n",
    "Steps:  \n",
    "- [ ] (1) Compute homography \\(H\\) using correspondences: **paris_a ‚Üí paris_b (base)**.  \n",
    "- [ ] (2) Warp and stitch **{paris_a, paris_b, paris_c}** onto the **paris_b** base frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd256d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Stitching Paris Images, with paris_b as base.\n",
    "base_path =  './tasks/1'\n",
    "\n",
    "\n",
    "img_paris_a = mpimg.imread('./images/paris/paris_a.jpg')\n",
    "img_paris_b = mpimg.imread('./images/paris/paris_b.jpg')\n",
    "img_paris_c = mpimg.imread('./images/paris/paris_c.jpg')\n",
    "\n",
    "# for all sample examples\n",
    "for sample_size in [4, 5, 6, 8, 10, 12, 15]:\n",
    "    result_save_path = base_path + f'/samples/{sample_size}_corresp/'\n",
    "    \n",
    "    # -- making one PANORAMIC img --\n",
    "    H_ab = homography_by_sample(f'./homography/paris/H_ab/samples/{sample_size}_corresp.npy')\n",
    "    H_cb = homography_by_sample(f'./homography/paris/H_cb/samples/{sample_size}_corresp.npy')\n",
    "    blended_mosaic = blend(mosaic([img_paris_a, img_paris_b ,img_paris_c], [H_ab, np.eye(3), H_cb]))\n",
    "    os.makedirs(result_save_path, exist_ok=True)\n",
    "    mpimg.imsave(result_save_path + f'panorama.jpg', blended_mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c819007d",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720b3d0",
   "metadata": {},
   "source": [
    "### left-to-right\n",
    "\n",
    "Let\n",
    "\n",
    "$$\n",
    "H_{A\\to B}\n",
    "$$\n",
    "\n",
    "denote the homography that maps coordinates from image $ A  ‚Üí  B $.\n",
    "\n",
    "Let $ I_{3√ó3} $ be the 3√ó3 identity matrix.\n",
    "\n",
    "\n",
    "---\n",
    "<div style =  \"text-align: center; font-weight: bold;\">\n",
    " Since our goal is to warp all imgs to left_2 img plane\n",
    "</div>\n",
    "\n",
    "\n",
    "$$\n",
    "H_{\\text{iter}}^{(0)} = I_{3\\times3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_{\\text{iter}}^{(1)} = H_{\\text{left}_1 \\to \\text{left}_2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_{\\text{iter}}^{(2)} = H_{\\text{left}_1 \\to \\text{left}_2} H_{\\text{middle}\\to\\text{left}_1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_{\\text{iter}}^{(3)} = H_{\\text{left}_1\\to\\text{left}_2} H_{\\text{middle}\\to\\text{left}_1} H_{\\text{right}_1\\to\\text{middle}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_{\\text{iter}}^{(4)} = H_{\\text{left}_1\\to\\text{left}_2} H_{\\text{middle}\\to\\text{left}_1} H_{\\text{right}_1\\to\\text{middle}} H_{\\text{right}_2\\to\\text{right}_1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21755dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "base_path =  './tasks/2'\n",
    "\n",
    "\n",
    "# Left To Right\n",
    "task_name = 'left_to_right'\n",
    "for sample_size in [4, 6, 8, 10, 12, 15]:\n",
    "    for building_name in ['cmpe_building']:\n",
    "        # getting base image\n",
    "        base_img = mpimg.imread(f'./images/{building_name}/left_2.jpg')\n",
    "        \n",
    "        # initial homography - identity\n",
    "        cumulative_homography = np.eye(3)\n",
    "        homographies = [np.eye(3)]\n",
    "        images = [base_img]\n",
    "        # path to save results\n",
    "        save_path = base_path + f'/{task_name}/{building_name}/samples/{sample_size}_corresp'\n",
    "        \n",
    "        # iterate over subsequent pairs\n",
    "        for prev_img_name, stitching_img_name, output_img_name in [\n",
    "            ['left_2.jpg', 'left_1.jpg', 'mosaic_1'],\n",
    "            ['left_1.jpg', 'middle.jpg', 'mosaic_2'], # instability at 10\n",
    "            ['middle.jpg', 'right_1.jpg', 'mosaic_3'],\n",
    "            ['right_1.jpg', 'right_2.jpg', 'mosaic_final']]:\n",
    "\n",
    "            # stitching {stitching_img} to left_2.jpg plane\n",
    "            stitching_img = mpimg.imread(f'images/{building_name}/{stitching_img_name}')\n",
    "            images.append(stitching_img)\n",
    "\n",
    "            # getting homography we already have in homography folder\n",
    "            sample_path = f'./homography/{building_name}/{stitching_img_name}->{prev_img_name}/samples/{sample_size}_corresp.npy'\n",
    "            H_to_prev = homography_by_sample(sample_path)\n",
    "            H_to_prev/=H_to_prev[2,2]\n",
    "            # getting homography from current (stitching_img) to leftmost\n",
    "            cumulative_homography = cumulative_homography @ H_to_prev\n",
    "            cumulative_homography /= cumulative_homography[2,2]\n",
    "            # add homography\n",
    "            homographies.append(cumulative_homography)\n",
    "            \n",
    "            # get mosaic\n",
    "            partial_mosaic = blend(mosaic(images, homographies))\n",
    "            \n",
    "            # warping {stitching_img} to leftmost img (left_2.jpg)\n",
    "            warp_result = warp_full(stitching_img, cumulative_homography)\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            mpimg.imsave(save_path + f'/{output_img_name}.jpg', partial_mosaic)\n",
    "            mpimg.imsave(save_path + f'/(warped){stitching_img_name}.jpg', warp_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a44a2",
   "metadata": {},
   "source": [
    "## **Middle-Out**\n",
    "<center>\n",
    "\n",
    "### **Image Notation**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_2 &\\equiv \\texttt{left\\_2.jpg}, \\\\\n",
    "L_1 &\\equiv \\texttt{left\\_1.jpg}, \\\\\n",
    "M   &\\equiv \\texttt{middle.jpg}, \\\\\n",
    "R_1 &\\equiv \\texttt{right\\_1.jpg}, \\\\\n",
    "R_2 &\\equiv \\texttt{right\\_2.jpg}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Given Pairwise Homographies**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_{L_1 \\to L_2}, \\quad\n",
    "H_{M \\to L_1}, \\quad\n",
    "H_{R_1 \\to M}, \\quad\n",
    "H_{R_2 \\to R_1}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Goal (Middle-Out Stitching Strategy)**\n",
    "\n",
    "1. Stitch $L_1$ and $R_1$ onto $M$ ‚Üí obtain $(\\text{mosaic}_1)$  \n",
    "2. Stitch $L_2$ and $R_2$ onto $\\text{mosaic}_1$ ‚Üí obtain $(\\text{mosaic}_{\\text{final}})$\n",
    "\n",
    "---\n",
    "\n",
    "### **Required Homographies (to Middle Coordinate Frame)**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_1 &= H_{L_1 \\to M} = (H_{M \\to L_1})^{-1}, \\\\[6pt]\n",
    "H_2 &= H_{R_1 \\to M}, \\\\[6pt]\n",
    "H_3 &= H_{L_2 \\to M} \n",
    "     = \\left(H_{L_1 \\to L_2} \\, H_{M \\to L_1}\\right)^{-1} \n",
    "     = (H_{M \\to L_2})^{-1}, \\\\[6pt]\n",
    "H_4 &= H_{R_2 \\to M} \n",
    "     = H_{R_1 \\to M} \\, H_{R_2 \\to R_1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Mosaic Construction**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{mosaic}_1 \n",
    "    &= \\text{blend}\\big(\\text{mosaic}([L_1, M, R_1], [H_1, I, H_2])\\big), \\\\[8pt]\n",
    "\\text{mosaic}_{\\text{final}} \n",
    "    &= \\text{blend}\\big(\\text{mosaic}([L_2, \\text{mosaic}_1, R_2], [H_3, I, H_4])\\big).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71835f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at sample_size = 12\n",
      "H1: [[ 1.21325503e+00 -1.40598382e-01 -6.64471378e+02]\n",
      " [ 1.37548368e-01  1.06695124e+00 -1.21495164e+02]\n",
      " [ 2.93400902e-04 -7.94582765e-05  8.41249024e-01]]\n",
      "H2: [[ 5.99424125e-01  1.04614609e-01  4.95460327e+02]\n",
      " [-1.17854479e-01  9.06883937e-01  4.93989215e+01]\n",
      " [-3.07230680e-04  7.08269677e-05  1.00000000e+00]]\n",
      "H3: [[ 1.21712679e+00 -1.31839572e-01 -1.49828732e+03]\n",
      " [ 2.92558822e-01  1.21405358e+00 -3.60877409e+02]\n",
      " [ 7.70157043e-04 -4.04306144e-05  3.12293682e-01]]\n",
      "H4: [[-9.59230142e-02 -6.17988414e-01  7.92332974e+02]\n",
      " [-1.87527619e-01  4.04367778e-01  1.08304646e+02]\n",
      " [-5.35354698e-04 -4.93309787e-04  8.63576013e-01]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'blend' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mH4:\u001b[39m\u001b[33m\"\u001b[39m, H4)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# mosaic and blend imgs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m mosaic_1 = \u001b[43mblend\u001b[49m(mosaic(images = [img_l1, img_m, img_r1], homographies = [H1, np.eye(\u001b[32m3\u001b[39m), H2]))\n\u001b[32m     40\u001b[39m mosaic_final = blend(mosaic(images = [img_l2, img_l1, img_m, img_r1, img_r2], homographies = [H3, H1, np.eye(\u001b[32m3\u001b[39m), H2, H4]))\n\u001b[32m     42\u001b[39m os.makedirs(save_path, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'blend' is not defined"
     ]
    }
   ],
   "source": [
    "# 2.2\n",
    "\n",
    "# Middle-out\n",
    "base_path =  './tasks/2'\n",
    "\n",
    "# Left To Right\n",
    "task_name = 'middle_out'\n",
    "# Middle-out\n",
    "base_path = './tasks/2'\n",
    "task_name = 'middle_out'\n",
    "\n",
    "for building_name in ['cmpe_building', 'north_campus']:\n",
    "    # load images\n",
    "    img_l1 = mpimg.imread(f'./images/{building_name}/left_1.jpg')\n",
    "    img_l2 = mpimg.imread(f'./images/{building_name}/left_2.jpg')\n",
    "    img_m  = mpimg.imread(f'./images/{building_name}/middle.jpg')\n",
    "    img_r1 = mpimg.imread(f'./images/{building_name}/right_1.jpg')\n",
    "    img_r2 = mpimg.imread(f'./images/{building_name}/right_2.jpg')\n",
    "\n",
    "    for sample_size in [12, 15]:\n",
    "        print(f'at sample_size = {sample_size}')\n",
    "        save_path = base_path + f'/{task_name}/{building_name}/samples/{sample_size}_corresp/'\n",
    "        # compute homographies\n",
    "        H1 = np.linalg.inv(homography_by_sample(f'./homography/{building_name}/middle.jpg->left_1.jpg/samples/{sample_size}_corresp.npy'))\n",
    "        H2 = homography_by_sample(f'./homography/{building_name}/right_1.jpg->middle.jpg/samples/{sample_size}_corresp.npy')\n",
    "        H3 = np.linalg.inv(\n",
    "            homography_by_sample(f'./homography/{building_name}/left_1.jpg->left_2.jpg/samples/{sample_size}_corresp.npy') @\n",
    "            homography_by_sample(f'./homography/{building_name}/middle.jpg->left_1.jpg/samples/{sample_size}_corresp.npy')\n",
    "        )\n",
    "        H4 = H2 @ homography_by_sample(f'./homography/{building_name}/right_2.jpg->right_1.jpg/samples/{sample_size}_corresp.npy')\n",
    "\n",
    "        # normalize\n",
    "        print(\"H1:\", H1)\n",
    "        print(\"H2:\", H2)\n",
    "        print(\"H3:\", H3)\n",
    "        print(\"H4:\", H4)\n",
    "\n",
    "        # mosaic and blend imgs\n",
    "        mosaic_1 = blend(mosaic(images = [img_l1, img_m, img_r1], homographies = [H1, np.eye(3), H2]))\n",
    "        mosaic_final = blend(mosaic(images = [img_l2, img_l1, img_m, img_r1, img_r2], homographies = [H3, H1, np.eye(3), H2, H4]))\n",
    "\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        mpimg.imsave(save_path + 'mosaic_1.jpg', mosaic_1)\n",
    "        mpimg.imsave(save_path + 'mosaic_final.jpg', mosaic_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a30c3",
   "metadata": {},
   "source": [
    "\n",
    "## **first-out-then-middle**\n",
    "<center>\n",
    "\n",
    "\n",
    "### **Given Pairwise Homographies**\n",
    "\n",
    "$$\n",
    "H_{L_1 \\to L_2} \\\\\n",
    "H_{M \\to L_1} \\\\\n",
    "H_{R_1 \\to M} \\\\\n",
    "H_{R_2 \\to R_1}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1 ‚Äî Left Mosaic (base: (L_1))**\n",
    "\n",
    "$$\n",
    "H_{L_2 \\to L_1} = (H_{L_1 \\to L_2})^{-1}, \\quad\n",
    "\\text{mosaic}*{\\text{left}} = \\text{blend}\\big([L_1, L_2], [I, H*{L_2 \\to L_1}]\\big)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2 ‚Äî Right Mosaic (base: (R_1))**\n",
    "\n",
    "$$\n",
    "H_{R_2 \\to R_1} \\text{ (given)}, \\quad\n",
    "\\text{mosaic}*{\\text{right}} = \\text{blend}\\big([R_1, R_2], [I, H*{R_2 \\to R_1}]\\big)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3 ‚Äî Final Mosaic (base: (M))**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_{L_1 \\to M} &= (H_{M \\to L_1})^{-1}, \\\\\n",
    "H_{L_2 \\to M} &= (H_{M \\to L_1} , H_{L_1 \\to L_2})^{-1}, \\\\\n",
    "H_{R_1 \\to M} &= H_{R_1 \\to M}, \\\\\n",
    "H_{R_2 \\to M} &= H_{R_1 \\to M} ,\\\\ H_{R_2 \\to R_1}, \\\\\n",
    "\\text{mosaic}*{\\text{final}} &= \\text{blend}\\big([\\text{mosaic}*{\\text{left}}, M, \\text{mosaic}*{\\text{right}}], [H*{L_1 \\to M}, I, H_{R_1 \\to M}]\\big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b37c9413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at sample_size = 12\n"
     ]
    }
   ],
   "source": [
    "# 2.3\n",
    "\n",
    "base_path =  './tasks/2'\n",
    "\n",
    "\n",
    "task_name = 'first-out-then-middle'\n",
    "\n",
    "for building_name in ['north_campus']:\n",
    "    # load images\n",
    "    img_l1 = mpimg.imread(f'./images/{building_name}/left_1.jpg')\n",
    "    img_l2 = mpimg.imread(f'./images/{building_name}/left_2.jpg')\n",
    "    img_m  = mpimg.imread(f'./images/{building_name}/middle.jpg')\n",
    "    img_r1 = mpimg.imread(f'./images/{building_name}/right_1.jpg')\n",
    "    img_r2 = mpimg.imread(f'./images/{building_name}/right_2.jpg')\n",
    "\n",
    "    for sample_size in [12]:\n",
    "        print(f'at sample_size = {sample_size}')\n",
    "        save_path = base_path + f'/{task_name}/{building_name}/samples/{sample_size}_corres/'\n",
    "        # compute homographies\n",
    "        H_l2l1 = np.linalg.inv(homography_by_sample(f'./homography/{building_name}/left_1.jpg->left_2.jpg/samples/{sample_size}_corresp.npy'))\n",
    "        H_r2r1 = homography_by_sample(f'./homography/{building_name}/right_2.jpg->right_1.jpg/samples/{sample_size}_corresp.npy')\n",
    "        H_l1m = np.linalg.inv(homography_by_sample(f'./homography/{building_name}/middle.jpg->left_1.jpg/samples/{sample_size}_corresp.npy'))\n",
    "        H_r1m = homography_by_sample(f'./homography/{building_name}/right_1.jpg->middle.jpg/samples/{sample_size}_corresp.npy')\n",
    "\n",
    "        # mosaic and blend imgs\n",
    "        mosaic_left = blend(mosaic(images = [img_l1, img_l2], homographies = [np.eye(3), H_l2l1]))\n",
    "        mosaic_right = blend(mosaic(images = [img_r1, img_r2], homographies = [np.eye(3), H_r2r1]))\n",
    "        mosaic_final = blend(mosaic(images = [img_l2, img_l1, img_m, img_r1, img_r2], homographies = [ H_l1m @ H_l2l1, H_l1m, np.eye(3), H_r1m, H_r1m @ H_r2r1 ]))\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        #mpimg.imsave(save_path + 'mosaic_left.jpg', mosaic_left)\n",
    "        #mpimg.imsave(save_path + 'mosaic_right.jpg', mosaic_right)\n",
    "        mpimg.imsave(save_path + 'mosaic_final.jpg', mosaic_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756a6cc",
   "metadata": {},
   "source": [
    "## Effects of Corresponding Points\n",
    "\n",
    "### Experimenting over Paris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71173cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/noisy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     54\u001b[39m H_cb_noisy = computeH(points_im1_noisy, points_im2_noisy)\n\u001b[32m     58\u001b[39m blended_mosaic = blend(mosaic([img_paris_a, img_paris_b ,img_paris_c], [H_ab_noisy, H_bb_noisy, H_cb_noisy]))\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m mpimg.imsave(result_save_path + \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpanorama.jpg\u001b[39m\u001b[33m'\u001b[39m, blended_mosaic)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/noisy'"
     ]
    }
   ],
   "source": [
    "# Noisy Corresp Points with Gausian\n",
    "\n",
    "img_paris_a = mpimg.imread('./images/paris/paris_a.jpg')\n",
    "img_paris_b = mpimg.imread('./images/paris/paris_b.jpg')\n",
    "img_paris_c = mpimg.imread('./images/paris/paris_c.jpg')\n",
    "\n",
    "\n",
    "\n",
    "def add_noise(points, sigma):\n",
    "    noisy_points = points + np.random.normal(0, sigma, points.shape)\n",
    "    return noisy_points\n",
    "\n",
    "# now, we can't just get homography since it'll use points without noise\n",
    "# get manually corresp points\n",
    "\n",
    "for sigma in [1, 5, 10]:\n",
    "\n",
    "    # for all simga examples\n",
    "    result_save_path = f'./noisy/{sigma}_sigma/'\n",
    "\n",
    "    # load saved sample info\n",
    "    points_ab  = np.load('./homography/paris/H_ab/samples/15_corresp.npy')\n",
    "    points_bb  = np.load('./homography/paris/H_bb/samples/15_corresp.npy')\n",
    "    points_cb  = np.load('./homography/paris/H_cb/samples/15_corresp.npy')\n",
    "\n",
    "    # compute homography AB\n",
    "    points_im1 = points_ab[:, 0]\n",
    "    points_im2 = points_ab[:, 1]\n",
    "    \n",
    "    points_im1_noisy = add_noise(points_im1, sigma)\n",
    "    points_im2_noisy = add_noise(points_im2, sigma)\n",
    "\n",
    "    H_ab_noisy = computeH(points_im1_noisy, points_im2_noisy)\n",
    "\n",
    "\n",
    "    # compute homography BB\n",
    "    points_im1 = points_bb[:, 0]\n",
    "    points_im2 = points_bb[:, 1]\n",
    "    \n",
    "    points_im1_noisy = add_noise(points_im1, sigma)\n",
    "    points_im2_noisy = add_noise(points_im2, sigma)\n",
    "\n",
    "    H_bb_noisy = computeH(points_im1_noisy, points_im2_noisy)\n",
    "\n",
    "\n",
    "\n",
    "    # compute homography CB\n",
    "    points_im1 = points_cb[:, 0]\n",
    "    points_im2 = points_cb[:, 1]\n",
    "    \n",
    "    points_im1_noisy = add_noise(points_im1, sigma)\n",
    "    points_im2_noisy = add_noise(points_im2, sigma)\n",
    "\n",
    "    H_cb_noisy = computeH(points_im1_noisy, points_im2_noisy)\n",
    "\n",
    "\n",
    "    \n",
    "    blended_mosaic = blend(mosaic([img_paris_a, img_paris_b ,img_paris_c], [H_ab_noisy, H_bb_noisy, H_cb_noisy]))\n",
    "    os.makedirs(result_save_path, exist_ok=True)\n",
    "    mpimg.imsave(result_save_path + f'panorama.jpg', blended_mosaic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
